{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Basic Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets import\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Data analysis with Excel\\Laptop price predictor\\laptop_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find out the missing value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicated rows\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the unnamed: 0 col\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catvars = df.select_dtypes(include=['object']).columns\n",
    "numvars = df.select_dtypes(include = ['int32','int64','float32','float64']).columns\n",
    "\n",
    "catvars,numvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniquevals(col):\n",
    "    print(f'Details of the particular col {col} is : {df[col].unique()}')\n",
    "    \n",
    "def valuecounts(col):\n",
    "    print(f'Valuecounts of the particular col {col} is : {df[col].value_counts()}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "for col in df.columns:\n",
    "    uniquevals(col)\n",
    "    print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "so on observation we can see that if we remove \"GB\" from RAM,i can \n",
    "make it as an integer value then after,now same goes with Memory as \n",
    "well as Weight,for Weight i can classify it as floating variable\n",
    "using the str.replace() as shown â†“\n",
    "'''\n",
    "\n",
    "df['Ram'] = df['Ram'].str.replace('GB','')\n",
    "df['Weight'] = df['Weight'].str.replace('kg','')\n",
    "\n",
    "# converting from string->integer for ram column\n",
    "\n",
    "df['Ram'] = df['Ram'].astype('int32')\n",
    "\n",
    "# converting from string-> float for the weight column\n",
    "\n",
    "df['Weight'] = df['Weight'].astype('float32')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do data analysis -> on price column\n",
    "# viewing the distribution of the price column\n",
    "\n",
    "sns.distplot(df['Price'],color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plotting countplots for the categorical variables\n",
    "\n",
    "def drawplot(col):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    sn.countplot(df[col],palette='plasma')\n",
    "    plt.xticks(rotation='vertical')\n",
    "    \n",
    "toview = ['Company', 'TypeName','Ram','OpSys']\n",
    "for col in toview:\n",
    "    drawplot(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average price for each of the laptop brands\n",
    "# this will say us the insight that as per company the price of the laptop vary\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sn.barplot(x = df['Company'],y = df['Price'])\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## various types of laptops\n",
    "\n",
    "sn.countplot(df['TypeName'],palette='autumn')\n",
    "plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laptop type and variation about the price \n",
    "\n",
    "sn.barplot(x = df['TypeName'],y = df['Price'])\n",
    "plt.xticks(rotation = 'vertical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variation of inches towards the price\n",
    "\n",
    "sn.scatterplot(x = df['Inches'],y = df['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the `Screen Resolution` column we have many types of Screen Resolutions out there as shown `Touch Screen` and `Normal` and `IPS Panel` are the 3 parts on basis of which we can segregate the things**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScreenResolution'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new col,touchscreen if the value is 1 that laptop is touch screen\n",
    "\n",
    "df['TouchScreen'] = df['ScreenResolution'].apply(lambda element:1 \n",
    "                                                      if 'Touchscreen' in element else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(df['TouchScreen'],palette='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# touch screen on comparision with price of laptop\n",
    "\n",
    "sn.barplot(x = df['TouchScreen'],y = df['Price'])\n",
    "plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new col named IPS,does the laptop have IPS facility or not\n",
    "\n",
    "df['IPS'] = df['ScreenResolution'].apply(\n",
    "    lambda element:1 if \"IPS\" in element else 0\n",
    ")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(df['IPS'],palette='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price variation with respect to the IPS col\n",
    "\n",
    "sn.barplot(x = df['TouchScreen'],y = df['Price'])\n",
    "plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the X Resolution and the Y Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will split the text at the \"x\" letter and seperate the 2 parts\n",
    "# from this we can observe that one of the col is Y res we need to do\n",
    "# some feature engineering on the X res col\n",
    "\n",
    "splitdf = df['ScreenResolution'].str.split('x',n = 1,expand=True)\n",
    "splitdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdf = df['ScreenResolution'].str.split('x',n = 1,expand=True)\n",
    "\n",
    "df['X_res'] = splitdf[0]\n",
    "df['Y_res'] = splitdf[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "So basically from that whole text of the X_res col,we need to \n",
    "extract the digits from it,but the problem is the numbers are scattered \n",
    "in some cases,that is the reason why i am using regex,if we use this\n",
    "we will exactly get the numbers which we are looking for!,\n",
    "so firstly replace all the \",\" with \"\" and then find all numbers\n",
    "from that string as \"\\d+\\.?\\d+\",\\d means that integer number and \\.? \n",
    "all the numbers which come after an number and \\d+ the string must end with number\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "df['X_res'] = df['X_res'].str.replace(',','').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x:x[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X_res'] = df['X_res'].astype('int')\n",
    "df['Y_res'] = df['Y_res'].astype('int')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sn.heatmap(df.corr(),annot=True,cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the correlation plot we observed that as the X_res and Y_res is increasing,the price of the laptop is also increasing,so `X_res and Y_res` are positively correlated and they are giving much information,so that is the reason why i had splitted `Resolution` column into `X_res and Y_res` columns respectively**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So to make things good,we can create a new column named `PPI{pixels per inch}`,now  as we saw from the correlation plot that the `X_res and Y_res` are having much collinearity,so why not combine them with `Inches` which is having less collinearity,so we will combine them as follows â†“,so here is the formula of how to calculate `PPI` {pixels per inch}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    PPI(pixels per inch) = \\frac{\\sqrt{X_resolution^2+Y_resolution^2}}{inches}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PPI'] = (((df['X_res']**2+df['Y_res']**2))**0.5/df['Inches']).astype('float')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So as we observe from the correlation data that the `PPI` is having good correlation,so we will be using that,as that is a combination of 3 features and that gives collective results of 3 columns,so we will drop `Inches,X_res,Y_res` as well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ScreenResolution','Inches','X_res','Y_res'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will work on `CPU` column,as that also has much text data and we need to process it efficiently as we may get good insights from them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cpu'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most common processors are made by intel right,so we will be clustering their `processors` into different categories like `i5,i7,other`,now other means the processors of intel which do not have i3,i5 or i7 attached to it,they're completely different so that's the reason i will clutter them into `other` and other category is `AMD` which is a different category in whole**\n",
    "\n",
    "**So if we observe we need to extract the first 3 words of the CPU column,as the first 3 words of every row under the CPU col is the type of the CPU,so we will be using them as shown â†“**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CPU_name'] = df['Cpu'].apply(lambda text:\" \".join(text.split()[:3]))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As mentioned earlier,if we get any of the intel `i3,i5 or i7` versions\n",
    "we will return them as it is,but if we get any other processor\n",
    "we will first check whether is that a variant of the intel? or not\n",
    "if yes,then we will tag it as \"Other Intel Processor\" else we will\n",
    "say it as `AMD Processor`\n",
    "\n",
    "'''\n",
    "\n",
    "def processortype(text):\n",
    "    \n",
    "    if text=='Intel Core i7' or text=='Intel Core i5' or text=='Intel Core i3':\n",
    "        return text\n",
    "    \n",
    "    else:\n",
    "        if text.split()[0]=='Intel':\n",
    "            return 'Other Intel Processor'\n",
    "        \n",
    "        else:\n",
    "            return 'AMD Processor'\n",
    "        \n",
    "    \n",
    "    \n",
    "df['CPU_name'] = df['CPU_name'].apply(lambda text:processortype(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(df['CPU_name'],palette='plasma')\n",
    "plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs processor variation\n",
    "\n",
    "sn.barplot(df['CPU_name'],df['Price'])\n",
    "plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping the cpu column\n",
    "\n",
    "df.drop(columns=['Cpu'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis on the RAM column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(df['Ram'],palette='autumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ram is having good relation with price\n",
    "\n",
    "sn.barplot(df['Ram'],df['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### About the memory column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will seperate the `Type` of memory and the value of it,just similar to the one which is done in the previous part**\n",
    "\n",
    "**This part involves things which are needed to be done in steps,so here we do not have the memory as a complete we have it in different dimension as `128GB SSD +  1TB HDD`,so inorder to for it come in a same dimension we need to do some modifications which are done below as shown**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Memory'].iloc[:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have different categories and also different kinds of variations \n",
    "\n",
    "df['Memory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4 most common variants observed : HHD,SSD,Flash,Hybrid\n",
    "\n",
    "# this expression will remove the decimal space for example 1.0 TB will be 1TB\n",
    "\n",
    "df['Memory'] = df['Memory'].astype(str).replace('\\.0','',regex = True)\n",
    "\n",
    "# replace the GB word with \" \"\n",
    "\n",
    "df['Memory'] = df['Memory'].str.replace('GB','')\n",
    "\n",
    "# replace the TB word with \"000\"\n",
    "\n",
    "df['Memory'] = df['Memory'].str.replace('TB','000')\n",
    "\n",
    "# split the word accross the \"+\" character\n",
    "\n",
    "newdf = df['Memory'].str.split(\"+\",n = 1,expand = True)\n",
    "\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will strip up all the white spaces,basically eliminating white space\n",
    "\n",
    "df['first'] = newdf[0]\n",
    "df['first'] = df['first'].str.strip()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applychanges(value):\n",
    "    \n",
    "    df['Layer1'+value] = df['first'].apply(lambda x:1 if value in x else 0)\n",
    "    \n",
    "    \n",
    "listtoapply = ['HDD','SSD','Hybrid','FlashStorage']    \n",
    "for value in listtoapply:\n",
    "    applychanges(value)\n",
    "    \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the characters just keep the numbers\n",
    "\n",
    "df['first'] = df['first'].str.replace(r'\\D','')\n",
    "df['first'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Second'] = newdf[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applychanges1(value):\n",
    "    \n",
    "    df['Layer2'+value] = df['Second'].apply(lambda x:1 if value in x else 0)\n",
    "    \n",
    "    \n",
    "listtoapply1 = ['HDD','SSD','Hybrid','FlashStorage']\n",
    "df['Second'] = df['Second'].fillna(\"0\")\n",
    "for value in listtoapply1:\n",
    "    applychanges1(value)\n",
    "    \n",
    "\n",
    "# remove all the characters just keep the numbers\n",
    "\n",
    "df['Second'] = df['Second'].str.replace(r'\\D','')\n",
    "df['Second'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first'] = df['first'].astype('int')\n",
    "df['Second'] = df['Second'].astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplying the elements and storing the result in subsequent columns\n",
    "\n",
    "\n",
    "df[\"HDD\"]=(df[\"first\"]*df[\"Layer1HDD\"]+df[\"Second\"]*df[\"Layer2HDD\"])\n",
    "df[\"SSD\"]=(df[\"first\"]*df[\"Layer1SSD\"]+df[\"Second\"]*df[\"Layer2SSD\"])\n",
    "df[\"Hybrid\"]=(df[\"first\"]*df[\"Layer1Hybrid\"]+df[\"Second\"]*df[\"Layer2Hybrid\"])\n",
    "df[\"Flash_Storage\"]=(df[\"first\"]*df[\"Layer1FlashStorage\"]+df[\"Second\"]*df[\"Layer2FlashStorage\"])\n",
    "\n",
    "\n",
    "## dropping of uncessary columns\n",
    "\n",
    "df.drop(columns=['first', 'Second', 'Layer1HDD', 'Layer1SSD', 'Layer1Hybrid',\n",
    "       'Layer1FlashStorage', 'Layer2HDD', 'Layer2SSD', 'Layer2Hybrid',\n",
    "       'Layer2FlashStorage'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Memory'],inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the correlation we observe that `Hybrid` and `Flash Storage` are almost negligible,so we can simply drop them off,where as HDD and SDD are having good correlation,we find that HDD has -ve relation with Price,and that's true,if the price of laptop is increasing there is more probability that the laptop is gonna use SDD instead of HDD and vice versa as well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Hybrid','Flash_Storage'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gpu'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here as we are having less data regarding the laptops,its better that we focus on `GPU brands` instead focusing on the values which are present there beside them,we will focus on the `brands`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what we will be doing,extracting the brands \n",
    "a = df['Gpu'].iloc[1]\n",
    "print(a.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gpu brand'] = df['Gpu'].apply(lambda x:x.split()[0])\n",
    "sn.countplot(df['Gpu brand'],palette='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the \"ARM\" tuple\n",
    "\n",
    "df = df[df['Gpu brand']!='ARM']\n",
    "sn.countplot(df['Gpu brand'],palette='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price-GPU analysis,i used np.median inorder to check if there is any\n",
    "# inpact of outlier or not\n",
    "\n",
    "sn.barplot(df['Gpu brand'],df['Price'],estimator=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Gpu'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Operating System analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OpSys'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.barplot(df['OpSys'],df['Price'])\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OpSys'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# club {Windows 10,Windows 7,Windows 7 S}-->Windows\n",
    "# club {macOS,mac OS X}--> mac\n",
    "# else return Others\n",
    "\n",
    "def setcategory(text):\n",
    "    \n",
    "    if text=='Windows 10' or text=='Windows 7' or text=='Windows 10 S':\n",
    "        return 'Windows'\n",
    "    \n",
    "    elif text=='Mac OS X' or text=='macOS':\n",
    "        return 'Mac'\n",
    "    \n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "    \n",
    "df['OpSys'] = df['OpSys'].apply(lambda x:setcategory(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(df['OpSys'],palette='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.barplot(x = df['OpSys'],y = df['Price'])\n",
    "plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weight analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df['Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.scatterplot(df['Weight'],df['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so if we apply np.log to the Price col we get a gaussian distibution\n",
    "\n",
    "sn.distplot(np.log(df['Price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation with price\n",
    "\n",
    "df.corr()['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sn.heatmap(df.corr(),annot=True,cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.log(df['Price'])\n",
    "train = df.drop(['Price'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                   test_size=0.15,random_state=2)\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There's a Class which we imported named as `Column Trasnformer` we use this widely while building our models using `Pipelines`,so for this we have to get the index numbers of the columns which are having categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {i:value for i,value in enumerate(X_train.columns)}\n",
    "mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply one hot encoding on the columns with this indices-->[0,1,3,8,11]\n",
    "# the remainder we keep as passthrough i.e no other col must get effected \n",
    "# except the ones undergoing the transformation!\n",
    "\n",
    "step1 = ColumnTransformer(transformers=[\n",
    "    ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,3,8,11])\n",
    "],remainder='passthrough')\n",
    "\n",
    "step2 = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1',step1),\n",
    "    ('step2',step2)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print('R2 score',metrics.r2_score(y_test,y_pred))\n",
    "print('MAE',metrics.mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now mae is 0.21 so if you want to check how much difference is there do this\n",
    "\n",
    "## we see there is a difference of 1.23 only as per the orignal value\n",
    "## that is our model predicts +-0.21 more/less than the original price!\n",
    "\n",
    "np.exp(0.21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply one hot encoding on the columns with this indices-->[0,1,3,8,11]\n",
    "# the remainder we keep as passthrough i.e no other col must get effected \n",
    "# except the ones undergoing the transformation!\n",
    "\n",
    "step1 = ColumnTransformer(transformers=[\n",
    "    ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,3,8,11])\n",
    "],remainder='passthrough')\n",
    "\n",
    "step2 = Ridge(alpha=10)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1',step1),\n",
    "    ('step2',step2)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print('R2 score',metrics.r2_score(y_test,y_pred))\n",
    "print('MAE',metrics.mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply one hot encoding on the columns with this indices-->[0,1,3,8,11]\n",
    "# the remainder we keep as passthrough i.e no other col must get effected \n",
    "# except the ones undergoing the transformation!\n",
    "\n",
    "step1 = ColumnTransformer(transformers=[\n",
    "    ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,3,8,11])\n",
    "],remainder='passthrough')\n",
    "\n",
    "step2 = Lasso(alpha=0.001)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1',step1),\n",
    "    ('step2',step2)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print('R2 score',metrics.r2_score(y_test,y_pred))\n",
    "print('MAE',metrics.mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply one hot encoding on the columns with this indices-->[0,1,3,8,11]\n",
    "# the remainder we keep as passthrough i.e no other col must get effected \n",
    "# except the ones undergoing the transformation!\n",
    "\n",
    "step1 = ColumnTransformer(transformers=[\n",
    "    ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,3,8,11])\n",
    "],remainder='passthrough')\n",
    "\n",
    "step2 = DecisionTreeRegressor(max_depth=8)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1',step1),\n",
    "    ('step2',step2)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print('R2 score',metrics.r2_score(y_test,y_pred))\n",
    "print('MAE',metrics.mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=[\n",
    "    ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,3,8,11])\n",
    "],remainder='passthrough')\n",
    "\n",
    "step2 = RandomForestRegressor(n_estimators=100,\n",
    "                              random_state=3,\n",
    "                              max_samples=0.5,\n",
    "                              max_features=0.75,\n",
    "                              max_depth=15)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1',step1),\n",
    "    ('step2',step2)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print('R2 score',metrics.r2_score(y_test,y_pred))\n",
    "print('MAE',metrics.mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(df,open('df1.pkl','wb'))\n",
    "pickle.dump(pipe,open('pipe1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('traineddata.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexlist = [0,1,3,8,11]\n",
    "transformlist = []\n",
    "for key,value in mapper.items():\n",
    "    if key in indexlist:\n",
    "        transformlist.append(value)\n",
    "        \n",
    "transformlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train,columns=transformlist,drop_first=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                   test_size=0.15,random_state=2)\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = DecisionTreeRegressor(random_state=0)\n",
    "reg.fit(X_train,y_train)\n",
    "plt.figure(figsize=(16,9))\n",
    "tree.plot_tree(reg,filled=True,feature_names=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = reg.cost_complexity_pruning_path(X_train,y_train)\n",
    "ccp_alphas = path.ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalist = []\n",
    "for alpha in ccp_alphas:\n",
    "    reg = DecisionTreeRegressor(random_state=0,ccp_alpha=alpha)\n",
    "    reg.fit(X_train,y_train)\n",
    "    alphalist.append(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = [reg.score(X_train,y_train) for reg in alphalist]\n",
    "test_score = [reg.score(X_test,y_test) for reg in alphalist]\n",
    "\n",
    "plt.xlabel('ccp alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.plot(ccp_alphas,train_score,marker = 'o',\n",
    "        label = 'training',color = 'magenta')\n",
    "plt.plot(ccp_alphas,test_score,marker = '+',\n",
    "         label = 'testing',color = 'red',drawstyle = 'steps-post')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**possible values of alpha can lie between `[0.0025-->0.0075]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = DecisionTreeRegressor(random_state=0,ccp_alpha=0.0085)\n",
    "reg.fit(X_train,y_train)\n",
    "plt.figure(figsize=(16,9))\n",
    "tree.plot_tree(reg,filled=True,feature_names=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=  {\n",
    "    \n",
    "    'RandomForest':{\n",
    "        'model' : RandomForestRegressor(),\n",
    "        'params':{\n",
    "            'n_estimators':[int(x) for x in np.linspace(100,1200,10)],\n",
    "            'criterion':[\"mse\", \"mae\"],\n",
    "            'max_depth':[int(x) for x in np.linspace(1,30,5)],\n",
    "            'max_features':['auto','sqrt','log2'],\n",
    "            'ccp_alpha':[x for x in np.linspace(0.0025,0.0125,5)],\n",
    "            'min_samples_split':[2,5,10,14],\n",
    "            'min_samples_leaf':[2,5,10,14],\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree':{\n",
    "        'model':DecisionTreeRegressor(),\n",
    "        'params':{\n",
    "            'criterion':[\"mse\", \"mae\"],\n",
    "            'max_depth':[int(x) for x in np.linspace(1,30,5)],\n",
    "            'max_features':['auto','sqrt','log2'],\n",
    "            'ccp_alpha':[x for x in np.linspace(0.0025,0.0125,5)],\n",
    "            'min_samples_split':[2,5,10,14],\n",
    "            'min_samples_leaf':[2,5,10,14],\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for modelname,mp in params.items():\n",
    "    clf = RandomizedSearchCV(mp['model'],\n",
    "                            param_distributions=mp['params'],cv = 5,\n",
    "                            n_iter=10,scoring='neg_mean_squared_error',verbose=2)\n",
    "    clf.fit(X_train,y_train)\n",
    "    scores.append({\n",
    "        'model_name':modelname,\n",
    "        'best_score':clf.best_score_,\n",
    "        'best_estimator':clf.best_estimator_,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores,columns=['model_name','best_score','best_estimator'])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(ccp_alpha=0.0025, max_depth=22, min_samples_leaf=14,\n",
    "                        min_samples_split=5, n_estimators=1200)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "ypred = rf.predict(X_test)\n",
    "print(metrics.r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "testtrain = np.array(train)\n",
    "for i in range(len(testtrain)):\n",
    "    predicted.append(rf.predict([testtrain[i]]))\n",
    "    \n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we transformed our price variable to np.log\n",
    "# we have to retranform it from np.log-->np.exp inorder to get the result\n",
    "\n",
    "ans = [np.exp(predicted[i][0]) for i in range(len(predicted))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Predicted Price'] = np.array(ans)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df['Price'],hist=False,color='orange',label='Actual')\n",
    "sn.distplot(df['Predicted Price'],hist=False,color='blue',label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor version_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestRegressor(n_estimators=100,\n",
    "                              random_state=3,\n",
    "                              max_samples=0.5,\n",
    "                              max_features=0.75,\n",
    "                              max_depth=15)\n",
    "\n",
    "rf1.fit(X_train,y_train)\n",
    "print(f'R2 score : {metrics.r2_score(y_test,rf1.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "testtrain = np.array(train)\n",
    "for i in range(len(testtrain)):\n",
    "    predicted.append(rf1.predict([testtrain[i]]))\n",
    "    \n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we transformed our price variable to np.log\n",
    "# we have to retranform it from np.log-->np.exp inorder to get the result\n",
    "\n",
    "ans = [np.exp(predicted[i][0]) for i in range(len(predicted))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(data['Price'],hist=False,color='orange',label='Actual')\n",
    "sn.distplot(data['Predicted Price'],hist=False,color='blue',label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('laptoppricepredictor.pkl','wb')\n",
    "pickle.dump(rf1,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
